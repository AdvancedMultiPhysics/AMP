// Class definitions for solver
#ifndef RAD_DIF_SOLVER
#define RAD_DIF_SOLVER

#include "AMP/IO/PIO.h"
#include "AMP/IO/AsciiWriter.h"
#include "AMP/utils/AMPManager.h"

#include "AMP/vectors/CommunicationList.h"
#include "AMP/matrices/petsc/NativePetscMatrix.h"
#include "AMP/vectors/VectorBuilder.h"
#include "AMP/vectors/Vector.h"
#include "AMP/vectors/MultiVector.h"
#include "AMP/vectors/MultiVariable.h"
#include "AMP/vectors/data/VectorData.h"
#include "AMP/vectors/data/VectorDataNull.h"
#include "AMP/vectors/operations/default/VectorOperationsDefault.h"
#include "AMP/vectors/VectorBuilder.h"

#include "AMP/discretization/boxMeshDOFManager.h"
#include "AMP/discretization/MultiDOF_Manager.h"
#include "AMP/mesh/Mesh.h"
#include "AMP/mesh/MeshID.h"
#include "AMP/mesh/MeshParameters.h"
#include "AMP/mesh/MeshElement.h"
#include "AMP/mesh/structured/BoxMesh.h"

#include "AMP/matrices/CSRMatrix.h"
#include "AMP/matrices/MatrixBuilder.h"

#include "AMP/operators/Operator.h"
#include "AMP/operators/OperatorParameters.h"
#include "AMP/operators/LinearOperator.h"
#include "AMP/operators/petsc/PetscMatrixShellOperator.h"
#include "AMP/operators/OperatorFactory.h"

#include "AMP/solvers/SolverFactory.h"
#include "AMP/solvers/SolverStrategy.h"
#include "AMP/solvers/testHelpers/SolverTestParameters.h"
#include "AMP/solvers/SolverStrategyParameters.h"
#include "AMP/solvers/SolverStrategy.h"
#include "AMP/solvers/SolverFactory.h"
#include "AMP/solvers/petsc/PetscSNESSolver.h"

#include "utils.hpp"
#include "discretization.hpp"

#include <iostream>
#include <iomanip>


/*
6.8.6 AMG for systems of PDEs
If the users wants to solve systems of PDEs and can provide information on which variables belong to which function, BoomerAMG’s systems AMG version can also be used. Functions that enable the user to access the systems AMG version are:
        a. HYPRE_BoomerAMGSetNumFunctions, 
        b. HYPRE_BoomerAMGSetDofFunc   
        c. HYPRE_BoomerAMGSetNodal.

    a. HYPRE_Int HYPRE_BoomerAMGSetNumFunctions(HYPRE_Solver solver, HYPRE_Int num_functions)
    (Optional) Sets the size of the system of PDEs, if using the systems version.
    The default is 1, i.e. a scalar system.
    ---this option is in AMP as "num_functions"
    ---I will set this to "2"

    b. HYPRE_Int HYPRE_BoomerAMGSetDofFunc(HYPRE_Solver solver, HYPRE_Int *dof_func)
    (Optional) Sets the mapping that assigns the function to each variable, if using the systems version. If no assignment is made and the number of functions is k > 1, the mapping generated is (0,1,. . . ,k-1,0,1,. . . ,k-1,. . . ).
    ---this is NOT available in AMP
    ---Bit confused: Did some checking chat GPT (it went around in a circle). This function maps from a row in the matrix to the index (0,1,...,k-1) of the variable that owns the row. If you build the matrix in nodal ordering then it has the default structure provided by this function.

    c. HYPRE_Int HYPRE_BoomerAMGSetNodal(HYPRE_Solver solver, HYPRE_Int nodal)
    (Optional) Sets whether to use the nodal systems coarsening.
    Should be used for linear systems generated from systems of PDEs. The default is 0 (unknown-based coarsening, only coarsens within same function). For the remaining options a nodal matrix is generated by applying a norm to the nodal blocks and applying the coarsening algorithm to this matrix.
    • 1 : Frobenius norm
    • 2 : sum of absolute values of elements in each block
    • 3 : largest element in each block (not absolute value)
    • 4 : row-sum norm
    • 6 : sum of all values in each block
    ---this option is in AMP as "nodal"


Smoothing:
==========
"To use the more complicated smoothers, e.g. block, Schwarz, ILU smoothers, it is necessary to use HYPRE_BoomerAMGSetSmoothType and HYPRE_BoomerAMGSetSmoothNumLevels"
---these options are in AMP with:
    "smooth_type" and "smooth_number_levels"

    * HYPRE_Int HYPRE_BoomerAMGSetSmoothNumLevels(HYPRE_Solver solver, HYPRE_Int
    smooth_num_levels)
    (Optional) Sets the number of levels for more complex smoothers.
    The smoothers, as defined by HYPRE_BoomerAMGSetSmoothType, will be used on level 0 (the finest
    level) through level smooth_num_levels-1. The default is 0, i.e. no complex smoothers are used

    * HYPRE_Int HYPRE_BoomerAMGSetSmoothType(HYPRE_Solver solver, HYPRE_Int smooth_type)
        (Optional) Enables the use of more complex smoothers.
    --this option is in AMP with "smooth_type"
    
    The following options exist for smooth_type
    • 6 : Schwarz (routines needed to set: 
            a. HYPRE_BoomerAMGSetDomainType,
            b. HYPRE_BoomerAMGSetOverlap, 
            c. HYPRE_BoomerAMGSetVariant,
            d. HYPRE_BoomerAMGSetSchwarzRlxWeight
        )

        a. HYPRE_Int HYPRE_BoomerAMGSetDomainType(HYPRE_Solver solver, HYPRE_Int domain_type)
        Defines the type of domain used for the Schwarz method.
        The following options exist for domain_type:
        • 0 : each point is a domain
        • 1 : each node is a domain (only of interest in “systems” AMG)
        • 2 : each domain is generated by agglomeration (default)
        --this option is in AMP with "schwarz_domain_type"

        b. HYPRE_Int HYPRE_BoomerAMGSetOverlap(HYPRE_Solver solver, HYPRE_Int overlap)
        (Optional) Defines the overlap for the Schwarz method.
        The following options exist for overlap:
        • 0 : no overlap
        • 1 : minimal overlap (default)
        • 2 : overlap generated by including all neighbors of domain boundaries
        --this option is NOT in AMP

        c. HYPRE_Int HYPRE_BoomerAMGSetVariant(HYPRE_Solver solver, HYPRE_Int variant)
        (Optional) Defines which variant of the Schwarz method is used.
        The following options exist for variant:
        • 0 : hybrid multiplicative Schwarz method (no overlap across processor boundaries)
        • 1 : hybrid additive Schwarz method (no overlap across processor boundaries)
        • 2 : additive Schwarz method
        • 3 : hybrid multiplicative Schwarz method (with overlap across processor boundaries)
        The default is 0.
        --this option is in AMP with "schwarz_variant"

        d. HYPRE_Int HYPRE_BoomerAMGSetSchwarzRlxWeight(HYPRE_Solver solver, HYPRE_Real
        schwarz_rlx_weight)
        (Optional) Defines a smoothing parameter for the additive Schwarz method
        --this option is in AMP with "schwarz_weight"


*/



class BERadDifOpJacMonolithic : public AMP::Solver::SolverStrategy {

public:

    // Keep a pointer to this to save having to down cast more than once 
    std::shared_ptr<BERadDifOpJac> d_BERadDifOpJac = nullptr;

    // Solver
    std::shared_ptr<AMP::Solver::SolverStrategy> d_solver = nullptr;

    // The base class has the following data:
    // d_iMaxIterations       = "max_iterations"
    // d_iDebugPrintInfoLevel = "print_info_level"
    // d_bUseZeroInitialGuess = "zero_initial_guess"
    // d_dAbsoluteTolerance   = "absolute_tolerance"
    // d_dRelativeTolerance   = "relative_tolerance"
    // d_bComputeResidual     = "compute_residual"

    BERadDifOpJacMonolithic( std::shared_ptr<AMP::Solver::SolverStrategyParameters> params )
    : SolverStrategy( params ) {

        if ( d_iDebugPrintInfoLevel > 1 )
            AMP::pout << "BERadDifOpJacMonolithic::BERadDifOpJacMonolithic() " << std::endl;
    };  

    // Used by SolverFactory to create a BERadDifOpJacMonolithic
    static std::unique_ptr<AMP::Solver::SolverStrategy> create( std::shared_ptr<AMP::Solver::SolverStrategyParameters> params ) {  
        return std::make_unique<BERadDifOpJacMonolithic>( params ); };

    // Implementation of pure virtual function
    std::string type() const { return "BERadDifOpJacMonolithic"; };

    // Apply preconditioner 
    // Incoming vectors are in variable ordering
    void apply(std::shared_ptr<const AMP::LinearAlgebra::Vector> bET_, std::shared_ptr< AMP::LinearAlgebra::Vector> ET_) override {

        if ( d_iDebugPrintInfoLevel > 2 )
            AMP::pout << "BERadDifOpJacMonolithic::apply() " << std::endl;


        // I don't think it makes sense to use a non-zero initial guess, does it?
        AMP_INSIST( d_bUseZeroInitialGuess, "Zero initial guess is hard coded!" );

        // Current implementation only supports a fixed number of iterations, ignores tolerances
        AMP_INSIST( d_dAbsoluteTolerance == 0.0 && d_dRelativeTolerance == 0.0, "Non-zero tolerances not implemented; only fixed number of iterations" );

        AMP_INSIST( this->getOperator(), "Apply requires an operator to be registered" );
        // Sometimes the d_pOperator variable is referenced directly rather than calling registerOperator... This call ensures our overridden registerOperator gets called
        registerOperator( this->getOperator() );


        // Convert variable-ordered vectors into nodal ordering
        // Create vectors for nodal ordering
        auto bET_ndl = d_BERadDifOpJac->createNodalInputVector();
        auto ET_ndl  = d_BERadDifOpJac->createNodalInputVector();
        d_BERadDifOpJac->createNodalOrderedCopy( bET_, bET_ndl );
        d_BERadDifOpJac->createNodalOrderedCopy( ET_, ET_ndl );
        ET_ndl->makeConsistent( AMP::LinearAlgebra::ScatterType::CONSISTENT_SET );
        bET_ndl->makeConsistent( AMP::LinearAlgebra::ScatterType::CONSISTENT_SET );

        // Create a residual and correction vectors 
        auto rET_ndl = d_BERadDifOpJac->createNodalInputVector();
        auto dET_ndl = d_BERadDifOpJac->createNodalInputVector();


        // Assemble solver
        setSolver();
        
        // --- Iterate ---
        // Set initial iterate to zero
        ET_ndl->zero( );
        for ( auto iter = 0; iter < d_iMaxIterations; iter++ ) {

            // Compute residual
            if ( iter == 0 ) {
                rET_ndl->copyVector( bET_ndl ); // Zero initial iterate means r0 = b - A*x0 = b
            } else {
                d_BERadDifOpJac->residualNodal( bET_ndl, ET_ndl, rET_ndl );
            }
            if ( d_iDebugPrintInfoLevel > 1 ) {
                AMP::pout << "BERadDifOpJacMonolithic::apply(): iteration " << iter << ":" << std::endl;
                auto rnorms = getDiscreteNorms( 1.0, rET_ndl );
                AMP::pout << "||r||=(" << rnorms[0] << "," << rnorms[1] << "," << rnorms[2] << ")" << std::endl;
            }

            // Solve M * dET = rET, for precoditioner M
            d_solver->apply( rET_ndl, dET_ndl );

            // Update solution: ET <- ET + rET
            ET_ndl->axpby( 1.0, 1.0, *dET_ndl ); // ET <- 1.0*ET + 1.0*dET 
            ET_ndl->makeConsistent( AMP::LinearAlgebra::ScatterType::CONSISTENT_SET );
        }

        // Display final residual; note that this residual calculation is unnecessary because the final iterate is calculated already, hence the flag 
        if ( d_bComputeResidual ) {
            AMP::pout << "BERadDifOpJacMonolithic::apply(): final residual" << ":" << std::endl;
            d_BERadDifOpJac->residualNodal( bET_ndl, ET_ndl, rET_ndl );
            auto rnorms = getDiscreteNorms( 1.0, rET_ndl );
            AMP::pout << "||r||=(" << rnorms[0] << "," << rnorms[1] << "," << rnorms[2] << ")" << std::endl;
        }

        // Copy output vector back to variable ordering
        d_BERadDifOpJac->createVariableOrderedCopy( ET_ndl, ET_ );
    }

    // Create solvers for diffusion blocks if they don't exist already
    void setSolver( ) {

        if ( d_solver )
            return;

        // Wrap matrix as LinearOperators 
        auto db    = AMP::Database::create( "name", "Operator", "print_info_level", 0 );
        auto params = std::make_shared<AMP::Operator::OperatorParameters>( std::move(db) );
        auto JacNodal = std::make_shared<AMP::Operator::LinearOperator>( params );
        JacNodal->setMatrix( d_BERadDifOpJac->d_JNodal );
        AMP_INSIST( JacNodal->getMatrix(), "Jac Matrix is null" );

        // Create solver parameters
        auto comm        = d_BERadDifOpJac->getMesh()->getComm(); 
        auto solver_db   = d_db->getDatabase( "MonolithicSolver" );
        auto solverParams = std::make_shared<AMP::Solver::SolverStrategyParameters>( solver_db );
        solverParams->d_pOperator = JacNodal;
        solverParams->d_comm      = comm;

        // Create solvers from Factories
        d_solver = AMP::Solver::SolverFactory::create( solverParams );
        // Ensure zero initial guess is used
        d_solver->setZeroInitialGuess( true );
    }


    void reset( std::shared_ptr<AMP::Solver::SolverStrategyParameters> params ) override {
        
        if ( d_iDebugPrintInfoLevel > 1 )
            AMP::pout << "BERadDifOpJacMonolithic::reset() " << std::endl;

        d_solver = nullptr;
    }

    void registerOperator( std::shared_ptr<AMP::Operator::Operator> op ) override {
        if ( d_iDebugPrintInfoLevel > 1 )
            AMP::pout << "BERadDifOpJacMonolithic::registerOperator() " << std::endl;

        AMP_INSIST( op, "A null operator cannot be registered" );

        d_pOperator = op;
        auto myBEOp = std::dynamic_pointer_cast<BERadDifOpJac>( op );
        AMP_INSIST( myBEOp, "Operator must be of BERadDifOpJac type" );
        d_BERadDifOpJac = myBEOp;
    }
};






/* An operator-split, block-based preconditioner for the LinearOperator 
        BERadDifOpJac = A == I + gamma*D + gamma*R,
    where D is a block-diagonal diffusion matrix, and R is a matrix with diagonal blocks

    The preconditioner matrix arises in factored form as
        P = P_dif * P_react = ( I + gamma*D ) * ( I + gamma*R )
    And is implemeneted as a stationary linear iteration to solve the linear system
        A*[E,T] = [bE,bT]
    The preconditioner is implemented as a stationary linear iteration of the form:
        [E,T] <- [E,T] + [dE,dT], where P*[dE,dT]=r, for residual r = [bE,bT]-A*[E,T].

    Note that one iteration of the preconditioner is equivalent to returning
        [E,T] = P^{-1} * [bE,bT].

    The inverse of ( I + gamma*D ) is carried out approximately by applying individual solvers to each of its diagonal blocks. The incoming Database must contain a 'DiffusionBlocks' Database with sufficient information for the corresponding solvers to be created from a Solverfactory.
*/
class BERadDifOpJacOpSplitPrec : public AMP::Solver::SolverStrategy {

public:

    // Keep a pointer to this to save having to down cast more than once 
    std::shared_ptr<BERadDifOpJac> d_BERadDifOpJac = nullptr;

    // Solvers for inverting diagonal diffusion blocks
    std::shared_ptr<AMP::Solver::SolverStrategy> d_dif_E_solver = nullptr;
    std::shared_ptr<AMP::Solver::SolverStrategy> d_dif_T_solver = nullptr;

    // The base class has the following data:
    // d_iMaxIterations       = "max_iterations"
    // d_iDebugPrintInfoLevel = "print_info_level"
    // d_bUseZeroInitialGuess = "zero_initial_guess"
    // d_dAbsoluteTolerance   = "absolute_tolerance"
    // d_dRelativeTolerance   = "relative_tolerance"
    // d_bComputeResidual     = "compute_residual"

    BERadDifOpJacOpSplitPrec( std::shared_ptr<AMP::Solver::SolverStrategyParameters> params )
    : SolverStrategy( params ) {

        if ( d_iDebugPrintInfoLevel > 1 )
            AMP::pout << "BERadDifOpJacOpSplitPrec::BERadDifOpJacOpSplitPrec() " << std::endl;
        
        // Ensure DiffusionBlocks Database was parsed.
        AMP_INSIST(  d_db->getDatabase( "DiffusionBlocks" ), "Preconditioner requires a 'DiffusionBlocks' database" );
    };  

    // Used by SolverFactory to create a BERadDifOpJacOpSplitPrec
    static std::unique_ptr<AMP::Solver::SolverStrategy> create( std::shared_ptr<AMP::Solver::SolverStrategyParameters> params ) {  
        return std::make_unique<BERadDifOpJacOpSplitPrec>( params ); };

    // Implementation of pure virtual function
    std::string type() const { return "BERadDifOpJacOpSplitPrec"; };

    // Apply preconditioner 
    // On p. 26 of Bobby's paper P = P_dif * P_react, so we first invert P_dif then P_react
    void apply(std::shared_ptr<const AMP::LinearAlgebra::Vector> bET_, std::shared_ptr< AMP::LinearAlgebra::Vector> ET_) override {

        // I don't think it makes sense to use a non-zero initial guess, does it?
        AMP_INSIST( d_bUseZeroInitialGuess, "Zero initial guess is hard coded!" );

        // Current implementation only supports a fixed number of iterations, ignores tolerances
        AMP_INSIST( d_dAbsoluteTolerance == 0.0 && d_dRelativeTolerance == 0.0, "Non-zero tolerances not implemented; only fixed number of iterations" );

        AMP_INSIST( this->getOperator(), "Apply requires an operator to be registered" );
        // Sometimes the d_pOperator variable is referenced directly rather than calling registerOperator... This call ensures our overridden registerOperator gets called
        registerOperator( this->getOperator() );

        // Assemble solvers for diffusion blocks
        setDiffusionSolvers();

        // --- Downcast input Vectors to MultiVectors ---
        auto bET = std::dynamic_pointer_cast<const AMP::LinearAlgebra::MultiVector>( bET_ );
        auto  ET = std::dynamic_pointer_cast<AMP::LinearAlgebra::MultiVector>( ET_ );
        AMP_INSIST( bET, "bET downcast to MultiVector unsuccessful" );
        AMP_INSIST(  ET, "ET downcast to MultiVector unsuccessful" );
        // Unpack scalar vectors from multivectors
        auto bE = bET->getVector(0);
        auto bT = bET->getVector(1);
        auto E  = ET->getVector(0);
        auto T  = ET->getVector(1);

        // Create a residual vector and upack it
        auto rET_ = d_BERadDifOpJac->createInputVector();
        auto rET  = std::dynamic_pointer_cast<AMP::LinearAlgebra::MultiVector>( rET_ );
        AMP_INSIST( rET, "rET downcast to MultiVector unsuccessful" );
        auto rE   = rET->getVector(0);
        auto rT   = rET->getVector(1); 
        // Create a correction vector and upack it
        auto dET_ = d_BERadDifOpJac->createInputVector();
        auto dET  = std::dynamic_pointer_cast<AMP::LinearAlgebra::MultiVector>( dET_ );
        AMP_INSIST( dET, "dET downcast to MultiVector unsuccessful" );
        auto dE   = dET->getVector(0);
        auto dT   = dET->getVector(1); 
        
        // --- Iterate ---
        // Set initial iterate to zero
        ET->zero( );
        for ( auto iter = 0; iter < d_iMaxIterations; iter++ ) {

            // Compute residual
            if ( iter == 0 ) {
                rET->copyVector( bET ); // Zero initial iterate means r0 = b - A*x0 = b
            } else {
                d_BERadDifOpJac->residual( bET, ET, rET );
            }
            if ( d_iDebugPrintInfoLevel > 1 ) {
                AMP::pout << "BERadDifOpJacOpSplitPrec::apply(): iteration " << iter << ":" << std::endl;
                auto rnorms = getDiscreteNorms( 1.0, rET );
                AMP::pout << "||r||=(" << rnorms[0] << "," << rnorms[1] << "," << rnorms[2] << ")" << std::endl;
            }

            // Solve P_dif * [dE, dT] = [rE, rT], with residuals r
            diffusionSolve( rE, rT, dE, dT );
            // Solve P_react * [rE, rT] = [dE, dT] (here we abuse variable names)
            reactionSolve( dE, dT, rE, rT );

            // Update solution: ET <- ET + rET
            ET->axpby( 1.0, 1.0, *rET ); // ET <- 1.0*ET + 1.0*rET 
            ET->makeConsistent( AMP::LinearAlgebra::ScatterType::CONSISTENT_SET );
        }

        // Display final residual; note that this residual calculation is unnecessary because the final iterate is calculated already, hence the flag 
        if ( d_bComputeResidual ) {
            d_BERadDifOpJac->residual( bET, ET, rET );
            AMP::pout << "BERadDifOpJacOpSplitPrec::apply(): final residual" << ":" << std::endl;
                auto rnorms = getDiscreteNorms( 1.0, rET );
                AMP::pout << "||r||=(" << rnorms[0] << "," << rnorms[1] << "," << rnorms[2] << ")" << std::endl;
        }
    }

    

    /* The base class' reset() does: 
        1. Call's it's operator's reset() with null OperatorParameters
        2. Call's it's nested solver's reset with the incoming params. 
        
    In this reset() we're not going to do anything because: 1. The underlying Operator is reset by other means, with appropriate parameters. The only data we store that would need to actually be reset are the solvers for the diffusion blocks, but these are fully reconstructed every time there's a call to apply(), since this is guaranteed to have the most up to date information anyway. */
    void reset( std::shared_ptr<AMP::Solver::SolverStrategyParameters> params ) override {
        //AMP_WARNING( "BERadDifOpJacOpSplitPrec::reset() doesn't do anything... What should it do?" );

        if ( d_iDebugPrintInfoLevel > 1 )
            AMP::pout << "BERadDifOpJacOpSplitPrec::reset() " << std::endl;

        d_dif_T_solver = nullptr;
        d_dif_E_solver = nullptr;
    }

    void registerOperator( std::shared_ptr<AMP::Operator::Operator> op ) override {
        if ( d_iDebugPrintInfoLevel > 1 )
            AMP::pout << "BERadDifOpJacOpSplitPrec::registerOperator() " << std::endl;

        AMP_INSIST( op, "A null operator cannot be registered" );

        d_pOperator = op;
        auto myBEOp = std::dynamic_pointer_cast<BERadDifOpJac>( op );
        AMP_INSIST( myBEOp, "Operator must be of BERadDifOpJac type" );
        d_BERadDifOpJac = myBEOp;
    }


private:

    /* Solve the diffusion system P_dif * [E,T] = [bE, bT] for [E,T] */
    void diffusionSolve(  
    std::shared_ptr<const AMP::LinearAlgebra::Vector> bE,
    std::shared_ptr<const AMP::LinearAlgebra::Vector> bT,
    std::shared_ptr<      AMP::LinearAlgebra::Vector>  E,
    std::shared_ptr<      AMP::LinearAlgebra::Vector>  T ) {
        AMP_INSIST( d_dif_E_solver, "Null dif_E_solver" );
        AMP_INSIST( d_dif_T_solver, "Null dif_T_solver" );
        d_dif_E_solver->apply( bE, E );
        d_dif_T_solver->apply( bT, T );
    }
    
    /* This solves the reaction system B*[E,T] = [bE, bT] for [E,T]
        Here we directly apply B^{-1}, where B == I + R_BE
            where R_BE = [ diag(r_EE_BE) diag(r_ET_BE) ]
                         [ diag(r_TE_BE) diag(r_TT_BE) ] 
    is a subset of the data stored in our opertor's d_data variable */
    void reactionSolve(  
        std::shared_ptr<const AMP::LinearAlgebra::Vector> bE,
        std::shared_ptr<const AMP::LinearAlgebra::Vector> bT,
        std::shared_ptr<      AMP::LinearAlgebra::Vector>  E,
        std::shared_ptr<      AMP::LinearAlgebra::Vector>  T ) {

        // Get Operator's data
        auto data = d_BERadDifOpJac->d_data;

        // Constants used to describe 2x2 linear systems
        double a, b, c, d, e, f, x, y;

        // Iterate through all local rows
        auto scalarDOFMan = d_BERadDifOpJac->d_RadDifOpJac->d_RadDifOp->d_scalarDOFMan;
        for (auto dof = scalarDOFMan->beginDOF(); dof != scalarDOFMan->endDOF(); dof++) {
            // LHS matrix
            a = data->r_EE_BE->getValueByGlobalID<double>( dof ) + 1.0; // Add identity 
            b = data->r_ET_BE->getValueByGlobalID<double>( dof );
            c = data->r_TE_BE->getValueByGlobalID<double>( dof );
            d = data->r_TT_BE->getValueByGlobalID<double>( dof ) + 1.0; // Add identity 
            // RHS
            e = bE->getValueByGlobalID<double>( dof );
            f = bT->getValueByGlobalID<double>( dof );
            // Solve linear system
            twoByTwoSolve( a, b, c, d, e, f, x, y );
            // Pack results into solution vectors
            E->setValueByGlobalID<double>( dof, x );
            T->setValueByGlobalID<double>( dof, y );
        }
    }

    /* Solve the linear system
        ax+by=e
        cx+dy=f 
    for x and y. */
    void twoByTwoSolve( double a, double b, double c, double d, double e, double f, double &x, double &y ) {
        double det = a*d - b*c;
        //AMP::pout << det << " = " << a << " x " << d << " - " << b << " x " << c << std::endl;
        AMP_INSIST( fabs( det ) > 1e-12, "2x2 linear system is singular" );
        x = (e*d - b*f) / det;
        y = (a*f - e*c) / det;
    }


    // Create solvers for diffusion blocks if they don't exist already
    void setDiffusionSolvers( ) {

        if ( d_dif_E_solver && d_dif_T_solver )
            return;

        // Wrap diffusion matrices as LinearOperators 
        // E
        auto E_db    = AMP::Database::create( "name", "EOperator", "print_info_level", 0 );
        auto EParams = std::make_shared<AMP::Operator::OperatorParameters>( std::move(E_db) );
        auto E       = std::make_shared<AMP::Operator::LinearOperator>( EParams );
        AMP_INSIST( d_BERadDifOpJac->d_data->d_E_BE, "E diffusion matrix is null" );
        E->setMatrix( d_BERadDifOpJac->d_data->d_E_BE );
        
        // T
        auto T_db    = AMP::Database::create( "name", "TOperator", "print_info_level", 0 );
        auto TParams = std::make_shared<AMP::Operator::OperatorParameters>( std::move(T_db) );
        auto T       = std::make_shared<AMP::Operator::LinearOperator>( TParams );
        T->setMatrix( d_BERadDifOpJac->d_data->d_T_BE );
        AMP_INSIST( T->getMatrix(), "T diffusion matrix is null" );

        // Create solver parameters
        auto comm        = d_BERadDifOpJac->getMesh()->getComm(); 
        auto solver_db   = d_db->getDatabase( "DiffusionBlocks" );
        // E
        auto ESolverParams = std::make_shared<AMP::Solver::SolverStrategyParameters>( solver_db );
        ESolverParams->d_pOperator = E;
        ESolverParams->d_comm      = comm;
        // T
        auto TSolverParams = std::make_shared<AMP::Solver::SolverStrategyParameters>( solver_db );
        TSolverParams->d_pOperator = T;
        TSolverParams->d_comm      = comm;

        // auto A = d_TOp->getMatrix();
        // AMP::IO::AsciiWriter matWriter;
        // matWriter.registerMatrix( A );
        // matWriter.writeFile( "Aout", 0  );

        // Create solvers from Factories
        d_dif_E_solver = AMP::Solver::SolverFactory::create( ESolverParams );
        d_dif_T_solver = AMP::Solver::SolverFactory::create( TSolverParams );
        // Ensure zero initial guess is used
        d_dif_E_solver->setZeroInitialGuess( true );
        d_dif_T_solver->setZeroInitialGuess( true );
    }

};




#endif